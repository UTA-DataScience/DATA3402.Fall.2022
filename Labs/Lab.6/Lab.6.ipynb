{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for SUSY Dataset\n",
    "\n",
    "Use the SUSY dataset for the rest of this lab. Here is a basic setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our usual libraries...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"../Lab.5/SUSY.csv\"\n",
    "VarNames=[\"signal\", \"l_1_pT\", \"l_1_eta\",\"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \n",
    "          \"l_2_phi\", \"MET\", \"MET_phi\", \"MET_rel\", \"axial_MET\",\n",
    "          \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos_theta_r1\"]\n",
    "df = pd.read_csv(filename, dtype='float64', names=VarNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "[Scikit-learn](http://scikit-learn.org) is a rich python library for data science, including machine learning. For example, we can build a Fisher Discriminant (aka Linear Discriminant Analysis, or LDA). \n",
    "\n",
    "### Exercise 1: Install Scikit-Learn\n",
    "\n",
    "Follow the [Installation Instructions](https://scikit-learn.org/stable/install.html) and install `scikit-learn` in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Read About Classifiers\n",
    "\n",
    "#### Part a\n",
    "Scikit-learn offers an impressively comprehensive list of machine learning algorithms. Browse through [scikit-learn's documentation](https://scikit-learn.org/stable/index.html). You'll note the algorithms are organized into classification, regression, clustering, dimensionality reduction, model selection, and preprocessing. Browse through the list of [classification algorithms](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning). \n",
    "\n",
    "#### Part b\n",
    "Note scikit-learn's documentation is rather comprehensive. The documentation on [linear models](https://scikit-learn.org/stable/modules/linear_model.html) shows how classification problems are setup. Read about the first few methods and try to comprehend the example codes. Skim the rest of the document.\n",
    "\n",
    "#### Part c\n",
    "Read through the [LDA Documentation](https://scikit-learn.org/stable/modules/lda_qda.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Training a Classifier\n",
    "\n",
    "Lets' repeat what we did manually in the previous lab using scikit-learn. We'll use a LDA classifier, which we can instanciate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.discriminant_analysis as DA\n",
    "Fisher=DA.LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the lecture, to properly formulate our problem, we'll have to:\n",
    "\n",
    "* Define the inputs (X) vs outputs (Y)\n",
    "* Designate training vs testing samples (in order to get a unbias assessment of the performance of Machine Learning algorithms)\n",
    "\n",
    "for example, here we'll take use 4M events for training and the remainder for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Train=4000000\n",
    "\n",
    "Train_Sample=df[:N_Train]\n",
    "Test_Sample=df[N_Train:]\n",
    "\n",
    "X_Train=Train_Sample[VarNames[1:]]\n",
    "y_Train=Train_Sample[\"signal\"]\n",
    "\n",
    "X_Test=Test_Sample[VarNames[1:]]\n",
    "y_Test=Test_Sample[\"signal\"]\n",
    "\n",
    "Test_sig=Test_Sample[Test_Sample.signal==1]\n",
    "Test_bkg=Test_Sample[Test_Sample.signal==0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the classifier as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher.fit(X_Train,y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the output, comparing signal and background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(Fisher.decision_function(Test_sig[VarNames[1:]]),bins=100,histtype=\"step\", color=\"blue\", label=\"signal\",stacked=True)\n",
    "plt.hist(Fisher.decision_function(Test_bkg[VarNames[1:]]),bins=100,histtype=\"step\", color=\"red\", label=\"background\",stacked=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "\n",
    "Compare ROC curves computed on the test versus training samples, in a single plot. Do you see a bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "\n",
    "Train the Fisher performance of using the raw, features, and raw+features as input. Compare the performance one a single plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Comparing Techniques\n",
    "\n",
    "#### Part a\n",
    "Select 3 different classifiers from the techniques listed [here](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning) to compare. Note that you can use the multi-layer perceptron to build a deep network, though training may be prohibitively slow. So avoid this technique.\n",
    "\n",
    "#### Part b\n",
    "\n",
    "Write a function that takes an instantiated classifier and performs the comparison from part 3b. Use the function on your choice of functions in part a.\n",
    "\n",
    "#### Part c\n",
    "\n",
    "Use the best method from part c to compute the maximal significance $\\sigma_S= \\frac{N_S}{\\sqrt{N_S+N_B}}$ for the scenarios in lab 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Metrics\n",
    "\n",
    "Scikit-learn provides methods for computing the FPR, TPR, ROC, AUC metrics. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_Test, Fisher.decision_function(X_Test))\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part a\n",
    "TPR/FPR/ROC/AUC are one way of assessing the quality of a classifier. Read about [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall), [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision), and [F-score](https://en.wikipedia.org/wiki/F-score).\n",
    "\n",
    "#### Part b\n",
    "Look through [model evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html#) documentation. Using scikit-learns tools, compute TPR, FPR, ROC, AUC, Precision, Recall, F1 score, and accuracy for the method you selected in 4c above and each scenario. Make a nice table, which also includes the maximal significance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
